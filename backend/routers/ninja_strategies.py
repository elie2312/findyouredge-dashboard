"""
Router pour les strat√©gies Ninja Trader
Lit les fichiers CSV du dossier ninja_runs
"""

from fastapi import APIRouter, HTTPException, Query
from fastapi.responses import FileResponse, JSONResponse
from pathlib import Path
import pandas as pd
import numpy as np
from typing import List, Dict, Any, Optional
import os
import json
from datetime import datetime

router = APIRouter()

# Chemin vers le dossier ninja_runs
BACKEND_PATH = Path(__file__).parent.parent
NINJA_RUNS_PATH = BACKEND_PATH.parent / "ninja_runs"


def clean_for_json(obj):
    """Nettoie r√©cursivement un objet pour la s√©rialisation JSON"""
    if isinstance(obj, dict):
        return {k: clean_for_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [clean_for_json(item) for item in obj]
    elif isinstance(obj, (np.integer, np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.floating, np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj):
            return None
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return clean_for_json(obj.tolist())
    elif pd.isna(obj):
        return None
    elif isinstance(obj, (int, float, str, bool, type(None))):
        if isinstance(obj, float) and (np.isnan(obj) or np.isinf(obj)):
            return None
        return obj
    else:
        return str(obj)


def calculate_strategy_stats(df: pd.DataFrame, filename: str = "") -> Dict[str, Any]:
    """Calcule les statistiques de base d'une strat√©gie"""
    
    print(f"\nüîç Analyse de {filename}")
    print(f"   Colonnes disponibles: {list(df.columns)}")
    print(f"   Nombre de lignes: {len(df)}")
    
    # D√©tection des colonnes pertinentes (flexible)
    pnl_col = None
    
    # Essayer diff√©rentes variantes de noms de colonnes
    possible_pnl_names = ['profit', 'pnl', 'b√©n√©fice', 'p&l', 'pl', 'net', 'gain', 'loss', 'result']
    
    for col in df.columns:
        col_lower = col.lower().strip()
        for pnl_name in possible_pnl_names:
            if pnl_name in col_lower:
                pnl_col = col
                print(f"   ‚úÖ Colonne PnL trouv√©e: '{col}'")
                break
        if pnl_col:
            break
    
    if pnl_col is None:
        # Essayer de trouver une colonne num√©rique qui pourrait √™tre le PnL
        numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()
        print(f"   Colonnes num√©riques: {numeric_cols}")
        if len(numeric_cols) > 0:
            # Prendre la derni√®re colonne num√©rique (souvent le PnL)
            pnl_col = numeric_cols[-1]
            print(f"   ‚ö†Ô∏è Utilisation de la colonne num√©rique: '{pnl_col}'")
    
    total_trades = len(df)
    
    if pnl_col and pnl_col in df.columns:
        print(f"   √âchantillon de valeurs brutes: {df[pnl_col].head().tolist()}")
        
        # Nettoyer les valeurs : enlever $, ‚Ç¨, espaces, remplacer virgule par point
        def clean_pnl_value(val):
            if pd.isna(val):
                return None
            val_str = str(val).strip()
            # Enlever les symboles mon√©taires et espaces
            val_str = val_str.replace('$', '').replace('‚Ç¨', '').replace(' ', '').replace(';', '')
            # Remplacer virgule par point pour les d√©cimales
            val_str = val_str.replace(',', '.')
            try:
                return float(val_str)
            except:
                return None
        
        pnl_values = df[pnl_col].apply(clean_pnl_value).dropna()
        print(f"   √âchantillon de valeurs nettoy√©es: {pnl_values.head().tolist()}")
        print(f"   Valeurs PnL apr√®s conversion: {len(pnl_values)} valeurs valides")
        
        if len(pnl_values) > 0:
            total_pnl = float(pnl_values.sum())
            winning_trades = len(pnl_values[pnl_values > 0])
            losing_trades = len(pnl_values[pnl_values < 0])
            winrate = (winning_trades / len(pnl_values) * 100) if len(pnl_values) > 0 else 0
            print(f"   üìä Stats: PnL={total_pnl:.2f}, W={winning_trades}, L={losing_trades}, WR={winrate:.1f}%")
        else:
            total_pnl = 0
            winning_trades = 0
            losing_trades = 0
            winrate = 0
    else:
        print(f"   ‚ùå Aucune colonne PnL trouv√©e!")
        total_pnl = 0
        winning_trades = 0
        losing_trades = 0
        winrate = 0
    
    # S'assurer que toutes les valeurs sont JSON-compatibles
    def safe_value(val):
        if val is None:
            return 0
        if isinstance(val, (int, float)):
            if np.isnan(val) or np.isinf(val):
                return 0
            return val
        return val
    
    return {
        "total_trades": int(safe_value(total_trades)),
        "total_pnl": round(float(safe_value(total_pnl)), 2),
        "winning_trades": int(safe_value(winning_trades)),
        "losing_trades": int(safe_value(losing_trades)),
        "winrate": round(float(safe_value(winrate)), 2),
        "pnl_column": pnl_col
    }


@router.get("")
def list_ninja_strategies(
    start_date: Optional[str] = Query(None, description="Date de d√©but (YYYY-MM-DD)"),
    end_date: Optional[str] = Query(None, description="Date de fin (YYYY-MM-DD)"),
    market: Optional[str] = Query(None, description="March√© √† filtrer (ex: NQ, ES, YM)")
):
    """
    Liste toutes les strat√©gies disponibles dans le dossier ninja_runs
    Peut filtrer par plage de dates et par march√©
    """
    if not NINJA_RUNS_PATH.exists():
        return {"strategies": [], "markets": []}
    
    strategies = []
    markets_set = set()
    
    try:
        # Scanner les fichiers CSV dans le dossier principal ET les sous-dossiers
        csv_files = []
        
        # Fichiers √† la racine (pour r√©trocompatibilit√©)
        csv_files.extend([(f, None) for f in NINJA_RUNS_PATH.glob("*.csv")])
        
        # Fichiers dans les sous-dossiers (march√©s)
        for market_dir in NINJA_RUNS_PATH.iterdir():
            if market_dir.is_dir():
                market_name = market_dir.name
                markets_set.add(market_name)
                for csv_file in market_dir.glob("*.csv"):
                    csv_files.append((csv_file, market_name))
        
        # Filtrer par march√© si sp√©cifi√©
        if market:
            csv_files = [(f, m) for f, m in csv_files if m == market]
        
        for csv_file, market_name in csv_files:
            try:
                # Lire le CSV avec d√©tection automatique du s√©parateur
                df = pd.read_csv(csv_file, sep=None, engine='python')
                
                # Filtrer par date si les param√®tres sont fournis
                if start_date or end_date:
                    print(f"\nüìÖ Filtrage demand√© pour {csv_file.name}: {start_date} -> {end_date}")
                    print(f"   Colonnes disponibles: {list(df.columns)}")
                    
                    # Chercher la colonne de date (plusieurs noms possibles, en priorit√© "Heure")
                    date_columns = [col for col in df.columns if 'heure' in col.lower() and 'sortie' in col.lower()]
                    
                    # Si pas trouv√©, chercher d'autres colonnes de date
                    if not date_columns:
                        date_columns = [col for col in df.columns if any(x in col.lower() for x in ['date', 'heure', 'time'])]
                    
                    print(f"   Colonnes de date trouv√©es: {date_columns}")
                    
                    if date_columns:
                        # Utiliser la premi√®re colonne de date trouv√©e (g√©n√©ralement "Heure de sortie")
                        date_col = date_columns[0]
                        print(f"   Utilisation de la colonne: {date_col}")
                        
                        try:
                            # Convertir en datetime avec format fran√ßais (DD/MM/YYYY)
                            df[date_col] = pd.to_datetime(df[date_col], format='%d/%m/%Y %H:%M:%S', errors='coerce')
                            
                            # Si √ßa n'a pas march√©, essayer d'autres formats
                            if df[date_col].isna().all():
                                df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
                            
                            print(f"   Lignes avant filtrage: {len(df)}")
                            print(f"   Plage de dates dans les donn√©es: {df[date_col].min()} -> {df[date_col].max()}")
                            
                            # Filtrer par date de d√©but
                            if start_date:
                                start_dt = pd.to_datetime(start_date)
                                print(f"   Filtre d√©but: {start_dt}")
                                df = df[df[date_col] >= start_dt]
                                print(f"   Lignes apr√®s filtre d√©but: {len(df)}")
                            
                            # Filtrer par date de fin
                            if end_date:
                                end_dt = pd.to_datetime(end_date) + pd.Timedelta(days=1)  # Inclure toute la journ√©e
                                print(f"   Filtre fin: {end_dt}")
                                df = df[df[date_col] < end_dt]
                                print(f"   Lignes apr√®s filtre fin: {len(df)}")
                        except Exception as e:
                            print(f"   ‚ùå Erreur lors du filtrage de date: {e}")
                    else:
                        print(f"   ‚ö†Ô∏è Aucune colonne de date trouv√©e!")
                
                # Calculer les stats sur les donn√©es filtr√©es
                stats = calculate_strategy_stats(df, csv_file.name)
                
                # Cr√©er un ID unique qui inclut le march√© si pr√©sent
                strategy_id = f"{market_name}/{csv_file.stem}" if market_name else csv_file.stem
                
                strategies.append({
                    "id": strategy_id,
                    "name": csv_file.stem,
                    "filename": csv_file.name,
                    "market": market_name,
                    "stats": stats
                })
            except Exception as e:
                print(f"Erreur lors de la lecture de {csv_file.name}: {e}")
                # Ajouter quand m√™me la strat√©gie avec des stats vides
                strategy_id = f"{market_name}/{csv_file.stem}" if market_name else csv_file.stem
                strategies.append({
                    "id": strategy_id,
                    "name": csv_file.stem,
                    "filename": csv_file.name,
                    "market": market_name,
                    "stats": {
                        "total_trades": 0,
                        "total_pnl": 0,
                        "winning_trades": 0,
                        "losing_trades": 0,
                        "winrate": 0
                    },
                    "error": str(e)
                })
        
        return {
            "strategies": strategies,
            "markets": sorted(list(markets_set))
        }
    
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors de la lecture des strat√©gies: {str(e)}"
        )


@router.get("/{strategy_id:path}/download")
def download_strategy_csv(strategy_id: str):
    """
    T√©l√©charge le fichier CSV brut d'une strat√©gie
    Supporte les chemins avec march√© (ex: NQ/Strategy1)
    """
    # Essayer d'abord avec le chemin complet (march√©/strat√©gie)
    csv_file = NINJA_RUNS_PATH / f"{strategy_id}.csv"
    
    if not csv_file.exists():
        raise HTTPException(
            status_code=404,
            detail=f"Fichier {strategy_id}.csv non trouv√©"
        )
    
    return FileResponse(
        path=csv_file,
        filename=csv_file.name,
        media_type="text/csv"
    )


@router.get("/{strategy_id:path}/data")
def get_strategy_data(
    strategy_id: str,
    start_date: Optional[str] = Query(None, description="Date de d√©but (YYYY-MM-DD)"),
    end_date: Optional[str] = Query(None, description="Date de fin (YYYY-MM-DD)")
):
    """
    R√©cup√®re les donn√©es d√©taill√©es d'une strat√©gie
    Peut filtrer par plage de dates
    Supporte les chemins avec march√© (ex: NQ/Strategy1)
    """
    csv_file = NINJA_RUNS_PATH / f"{strategy_id}.csv"
    
    if not csv_file.exists():
        raise HTTPException(
            status_code=404,
            detail=f"Fichier {strategy_id}.csv non trouv√©"
        )
    
    try:
        # Lire le CSV avec d√©tection automatique du s√©parateur
        df = pd.read_csv(csv_file, sep=None, engine='python')
        
        # Filtrer par date si les param√®tres sont fournis
        if start_date or end_date:
            print(f"\nüìÖ Filtrage demand√© pour {csv_file.name}: {start_date} -> {end_date}")
            
            # Chercher la colonne de date
            date_columns = [col for col in df.columns if 'heure' in col.lower() and 'sortie' in col.lower()]
            if not date_columns:
                date_columns = [col for col in df.columns if any(x in col.lower() for x in ['date', 'heure', 'time'])]
            
            if date_columns:
                date_col = date_columns[0]
                print(f"   Utilisation de la colonne: {date_col}")
                
                try:
                    # Convertir en datetime
                    df[date_col] = pd.to_datetime(df[date_col], format='%d/%m/%Y %H:%M:%S', errors='coerce')
                    if df[date_col].isna().all():
                        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
                    
                    print(f"   Lignes avant filtrage: {len(df)}")
                    
                    # Filtrer
                    if start_date:
                        start_dt = pd.to_datetime(start_date)
                        df = df[df[date_col] >= start_dt]
                    if end_date:
                        end_dt = pd.to_datetime(end_date) + pd.Timedelta(days=1)
                        df = df[df[date_col] < end_dt]
                    
                    print(f"   Lignes apr√®s filtrage: {len(df)}")
                except Exception as e:
                    print(f"   ‚ùå Erreur filtrage: {e}")
        
        stats = calculate_strategy_stats(df, csv_file.name)
        
        # Debug: v√©rifier les valeurs des colonnes probl√©matiques
        print(f"\nüîç V√©rification des colonnes:")
        col_prix_entree = "Prix d'entr√©e"
        col_heure_entree = "Heure d'entr√©e"
        col_prix_sortie = "Prix de sortie"
        
        if col_prix_entree in df.columns:
            print(f"   Prix d'entr√©e - Valeurs uniques: {df[col_prix_entree].unique()[:5]}")
        else:
            print(f"   ‚ö†Ô∏è Colonne '{col_prix_entree}' non trouv√©e")
            
        if col_heure_entree in df.columns:
            print(f"   Heure d'entr√©e - Valeurs uniques: {df[col_heure_entree].unique()[:5]}")
        else:
            print(f"   ‚ö†Ô∏è Colonne '{col_heure_entree}' non trouv√©e")
            
        if col_prix_sortie in df.columns:
            print(f"   Prix de sortie - Valeurs uniques: {df[col_prix_sortie].unique()[:5]}")
        else:
            print(f"   ‚ö†Ô∏è Colonne '{col_prix_sortie}' non trouv√©e")
        
        # Convertir le DataFrame en liste de dictionnaires
        # Remplacer NaN et Infinity par None pour la s√©rialisation JSON
        df_clean = df.copy()
        df_clean = df_clean.replace([np.inf, -np.inf], None)
        df_clean = df_clean.where(pd.notna(df_clean), None)
        
        # Convertir en dictionnaire
        trades = df_clean.to_dict('records')
        
        # Nettoyer les valeurs pour s'assurer qu'elles sont JSON-compatibles
        for trade in trades:
            for key, value in trade.items():
                if isinstance(value, (np.integer, np.floating)):
                    if np.isnan(value) or np.isinf(value):
                        trade[key] = None
                    else:
                        trade[key] = float(value) if isinstance(value, np.floating) else int(value)
        
        # G√©n√©rer la courbe d'√©quit√©
        pnl_col = stats.get('pnl_column')
        equity_curve = []
        if pnl_col and pnl_col in df.columns:
            # Fonction de nettoyage des valeurs PnL
            def clean_pnl_value(val):
                if pd.isna(val):
                    return None
                val_str = str(val).strip()
                val_str = val_str.replace('$', '').replace('‚Ç¨', '').replace(' ', '').replace(';', '')
                val_str = val_str.replace(',', '.')
                try:
                    return float(val_str)
                except:
                    return None
            
            cumulative_pnl = 0
            for idx, row in df.iterrows():
                pnl = clean_pnl_value(row[pnl_col])
                if pnl is not None and not np.isnan(pnl) and not np.isinf(pnl):
                    cumulative_pnl += pnl
                    # V√©rifier que cumulative_pnl est valide
                    if not np.isnan(cumulative_pnl) and not np.isinf(cumulative_pnl):
                        equity_curve.append({
                            "trade": int(idx) + 1,
                            "equity": round(float(cumulative_pnl), 2)
                        })
        
        # Pr√©parer la r√©ponse et la nettoyer
        response_data = {
            "id": strategy_id,
            "name": strategy_id,
            "stats": stats,
            "trades": trades,
            "columns": list(df.columns),
            "equity_curve": equity_curve
        }
        
        # Nettoyer toutes les valeurs pour JSON
        cleaned_data = clean_for_json(response_data)
        
        return JSONResponse(content=cleaned_data)
    
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Erreur lors de la lecture du fichier: {str(e)}"
        )
